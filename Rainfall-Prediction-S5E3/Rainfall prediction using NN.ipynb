{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91714,"databundleVersionId":11251744,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T19:03:50.960650Z","iopub.execute_input":"2025-03-10T19:03:50.961008Z","iopub.status.idle":"2025-03-10T19:03:51.353965Z","shell.execute_reply.started":"2025-03-10T19:03:50.960978Z","shell.execute_reply":"2025-03-10T19:03:51.353030Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s5e3/sample_submission.csv\n/kaggle/input/playground-series-s5e3/train.csv\n/kaggle/input/playground-series-s5e3/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import warnings\n\nwarnings.simplefilter(action=\"ignore\", category=FutureWarning)\n\ntrain_data_rt = \"/kaggle/input/playground-series-s5e3/train.csv\"\ntest_data_rt = \"/kaggle/input/playground-series-s5e3/test.csv\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T19:03:51.355312Z","iopub.execute_input":"2025-03-10T19:03:51.355911Z","iopub.status.idle":"2025-03-10T19:03:51.360169Z","shell.execute_reply.started":"2025-03-10T19:03:51.355871Z","shell.execute_reply":"2025-03-10T19:03:51.359209Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import torch.nn as nn\nimport torch\n\n# Initializing The model\n\nclass RainfallClassifierModel(nn.Module):\n    def __init__(self):\n        super(RainfallClassifierModel, self).__init__()\n        self.base_layers = nn.Sequential(\n            nn.Linear(54, 256),\n            nn.ReLU(),\n            nn.BatchNorm1d(256),\n            # nn.Dropout(0.2),  # 20% dropout\n    \n            nn.Linear(256, 512),\n            nn.ReLU(),\n            nn.BatchNorm1d(512),\n            # nn.Dropout(0.3),\n\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.BatchNorm1d(512),\n            # nn.Dropout(0.3),\n\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.BatchNorm1d(256),\n            # nn.Dropout(0.2),\n\n            nn.Linear(256, 1)\n)\n        self.flatten = nn.Flatten()\n        \n    def forward(self, x):\n        x = self.flatten(x)\n        x = self.base_layers(x)\n\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T19:03:51.362214Z","iopub.execute_input":"2025-03-10T19:03:51.362457Z","iopub.status.idle":"2025-03-10T19:03:55.487741Z","shell.execute_reply.started":"2025-03-10T19:03:51.362436Z","shell.execute_reply":"2025-03-10T19:03:55.486690Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Definfing the feature engineering process\n\ndef feature_engineering(df):\n    \"\"\"\n    Create new features based on meteorological understanding and data analysis,\n    with 'day' representing day of the year (1-365).\n    Ensures no data leakage by avoiding use of the target variable (rainfall).\n    \"\"\"\n    # Make a copy to avoid modifying the original dataframe\n    enhanced_df = df.copy()\n    \n    # 1. temparature range (difference between max and min temparatures)\n    enhanced_df['temp_range'] = enhanced_df['maxtemp'] - enhanced_df['mintemp']\n    \n    # 2. Dew point depression (difference between temparature and dew point)\n    enhanced_df['dewpoint_depression'] = enhanced_df['temparature'] - enhanced_df['dewpoint']\n    \n    # 3. Pressure change from previous day\n    enhanced_df['pressure_change'] = enhanced_df['pressure'].diff().fillna(0)\n    \n    # 4. Humidity to dew point ratio\n    enhanced_df['humidity_dewpoint_ratio'] = enhanced_df['humidity'] / enhanced_df['dewpoint'].clip(lower=0.1)\n    \n    # 5. Cloud coverage to sunshine ratio (inverse relationship)\n    enhanced_df['cloud_sunshine_ratio'] = enhanced_df['cloud'] / enhanced_df['sunshine'].clip(lower=0.1)\n    \n    # 6. Wind intensity factor (combination of speed and humidity)\n    enhanced_df['wind_humidity_factor'] = enhanced_df['windspeed'] * (enhanced_df['humidity'] / 100)\n    \n    # 7. temparature-humidity index (simple version of heat index)\n    enhanced_df['temp_humidity_index'] = (0.8 * enhanced_df['temparature']) + \\\n                                        ((enhanced_df['humidity'] / 100) * \\\n                                        (enhanced_df['temparature'] - 14.3)) + 46.4\n    \n    # 8. Pressure change rate (acceleration)\n    enhanced_df['pressure_acceleration'] = enhanced_df['pressure_change'].diff().fillna(0)\n    \n    # 9. Seasonal features (based on day of year)\n    # Convert day to month (1-365 to 1-12)\n    enhanced_df['month'] = ((enhanced_df['day'] - 1) // 30) + 1\n    enhanced_df['month'] = enhanced_df['month'].clip(upper=12)  # Ensure month doesn't exceed 12\n    \n    # 10. Convert day to season (1-365 to 1-4)\n    enhanced_df['season'] = ((enhanced_df['month'] - 1) // 3) + 1\n    \n    # 11. Sine and cosine transformations to capture cyclical nature of days in a year\n    enhanced_df['day_of_year_sin'] = np.sin(2 * np.pi * enhanced_df['day'] / 365)\n    enhanced_df['day_of_year_cos'] = np.cos(2 * np.pi * enhanced_df['day'] / 365)\n    \n    # 12. Rolling averages for key meteorological variables\n    for window in [3, 7, 14]:\n        enhanced_df[f'temparature_rolling_{window}d'] = enhanced_df['temparature'].rolling(window=window, min_periods=1).mean()\n        enhanced_df[f'pressure_rolling_{window}d'] = enhanced_df['pressure'].rolling(window=window, min_periods=1).mean()\n        enhanced_df[f'humidity_rolling_{window}d'] = enhanced_df['humidity'].rolling(window=window, min_periods=1).mean()\n        enhanced_df[f'cloud_rolling_{window}d'] = enhanced_df['cloud'].rolling(window=window, min_periods=1).mean()\n        enhanced_df[f'windspeed_rolling_{window}d'] = enhanced_df['windspeed'].rolling(window=window, min_periods=1).mean()\n    \n    # 13. Weather pattern change features\n    # temparature trend\n    enhanced_df['temp_trend_3d'] = enhanced_df['temparature'].diff(3).fillna(0)\n    # Pressure trend\n    enhanced_df['pressure_trend_3d'] = enhanced_df['pressure'].diff(3).fillna(0)\n    # Humidity trend\n    enhanced_df['humidity_trend_3d'] = enhanced_df['humidity'].diff(3).fillna(0)\n    \n    # 14. Extreme weather indicators\n    enhanced_df['extreme_temp'] = (enhanced_df['temparature'] > enhanced_df['temparature'].quantile(0.95)) | \\\n                                 (enhanced_df['temparature'] < enhanced_df['temparature'].quantile(0.05))\n    enhanced_df['extreme_temp'] = enhanced_df['extreme_temp'].astype(int)\n    \n    enhanced_df['extreme_humidity'] = (enhanced_df['humidity'] > enhanced_df['humidity'].quantile(0.95)) | \\\n                                     (enhanced_df['humidity'] < enhanced_df['humidity'].quantile(0.05))\n    enhanced_df['extreme_humidity'] = enhanced_df['extreme_humidity'].astype(int)\n    \n    enhanced_df['extreme_pressure'] = (enhanced_df['pressure'] > enhanced_df['pressure'].quantile(0.95)) | \\\n                                     (enhanced_df['pressure'] < enhanced_df['pressure'].quantile(0.05))\n    enhanced_df['extreme_pressure'] = enhanced_df['extreme_pressure'].astype(int)\n    \n    # 15. Interaction terms between key variables\n    enhanced_df['temp_humidity_interaction'] = enhanced_df['temparature'] * enhanced_df['humidity']\n    enhanced_df['pressure_wind_interaction'] = enhanced_df['pressure'] * enhanced_df['windspeed']\n    enhanced_df['cloud_sunshine_interaction'] = enhanced_df['cloud'] * enhanced_df['sunshine']\n    enhanced_df['dewpoint_humidity_interaction'] = enhanced_df['dewpoint'] * enhanced_df['humidity']\n    \n    # 16. Moving standard deviations for measuring variability\n    for window in [7, 14]:\n        enhanced_df[f'temp_std_{window}d'] = enhanced_df['temparature'].rolling(window=window, min_periods=4).std().fillna(0)\n        enhanced_df[f'pressure_std_{window}d'] = enhanced_df['pressure'].rolling(window=window, min_periods=4).std().fillna(0)\n        enhanced_df[f'humidity_std_{window}d'] = enhanced_df['humidity'].rolling(window=window, min_periods=4).std().fillna(0)\n    \n    return enhanced_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T19:03:55.489139Z","iopub.execute_input":"2025-03-10T19:03:55.489692Z","iopub.status.idle":"2025-03-10T19:03:55.503183Z","shell.execute_reply.started":"2025-03-10T19:03:55.489662Z","shell.execute_reply":"2025-03-10T19:03:55.502272Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train_data = pd.read_csv(train_data_rt)\ntest_data = pd.read_csv(test_data_rt)\nindices = test_data['id']\ntest_data = test_data.drop(columns = [\"id\"])\n\ntrain_data_fe = feature_engineering(train_data)\ntest_data_fe = feature_engineering(test_data).to_numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T19:03:55.504121Z","iopub.execute_input":"2025-03-10T19:03:55.504477Z","iopub.status.idle":"2025-03-10T19:03:55.640114Z","shell.execute_reply.started":"2025-03-10T19:03:55.504453Z","shell.execute_reply":"2025-03-10T19:03:55.639125Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Creating the custom dataloader for loading the data\n\nfrom torch.utils.data import Dataset, DataLoader\n\nclass CSVDataset(Dataset):\n    def __init__(self, df):\n        self.data = df.drop(columns = [\"id\", \"rainfall\"]).values # In order to load them as a numpy array\n        self.target = df[\"rainfall\"].values\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        features = torch.tensor(self.data[idx, :], dtype = torch.float32)\n        labels = torch.tensor(self.target[idx], dtype = torch.float32)\n\n        return features, labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T19:03:55.640964Z","iopub.execute_input":"2025-03-10T19:03:55.641208Z","iopub.status.idle":"2025-03-10T19:03:55.647333Z","shell.execute_reply.started":"2025-03-10T19:03:55.641188Z","shell.execute_reply":"2025-03-10T19:03:55.646246Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Initializing the model and other functionalities\nimport torch.optim as optim\n\nmodel = RainfallClassifierModel()\noptimizer = optim.SGD(model.parameters(), lr = 0.0001)\ncriterion = nn.BCEWithLogitsLoss()\n\ndataset = CSVDataset(train_data_fe)\ndataloader = DataLoader(dataset, batch_size = 10, shuffle = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T19:03:55.648289Z","iopub.execute_input":"2025-03-10T19:03:55.648644Z","iopub.status.idle":"2025-03-10T19:03:58.028544Z","shell.execute_reply.started":"2025-03-10T19:03:55.648612Z","shell.execute_reply":"2025-03-10T19:03:58.027630Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Function to initialize weights\n\nimport torch.nn.init as init\n\ndef initialize_weights(model, init_type=\"xavier\"):\n    for m in model.modules():\n        if isinstance(m, nn.Linear):  # Apply to linear layers\n            if init_type == \"xavier\":\n                init.xavier_uniform_(m.weight)  # Xavier initialization\n            elif init_type == \"he\":\n                init.kaiming_uniform_(m.weight, nonlinearity='relu')  # He initialization\n            elif init_type == \"orthogonal\":\n                init.orthogonal_(m.weight)  # Orthogonal initialization\n            else:\n                raise ValueError(\"Unknown initialization type\")\n            if m.bias is not None:\n                init.zeros_(m.bias)  # Initialize bias to zero\n\ninitialize_weights(model, init_type = \"he\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T19:03:58.030987Z","iopub.execute_input":"2025-03-10T19:03:58.031408Z","iopub.status.idle":"2025-03-10T19:03:58.042823Z","shell.execute_reply.started":"2025-03-10T19:03:58.031380Z","shell.execute_reply":"2025-03-10T19:03:58.041720Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Training Code\n\nnum_of_epochs = 50\n\nfor i in range(num_of_epochs):\n    model.train()\n    for batch_x, batch_y in dataloader:\n        optimizer.zero_grad()\n        y_pred = model(batch_x).squeeze(1)\n        \n        loss = criterion(y_pred, batch_y.float())  # BCE loss\n        \n        loss.backward()\n        optimizer.step()\n    print(f\"Epoch : {i} --------- Loss : {loss}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T19:03:58.044036Z","iopub.execute_input":"2025-03-10T19:03:58.044392Z","iopub.status.idle":"2025-03-10T19:04:33.355885Z","shell.execute_reply.started":"2025-03-10T19:03:58.044363Z","shell.execute_reply":"2025-03-10T19:04:33.354634Z"}},"outputs":[{"name":"stdout","text":"Epoch : 0 --------- Loss : 0.5543626546859741\nEpoch : 1 --------- Loss : 0.9438101649284363\nEpoch : 2 --------- Loss : 0.5250009298324585\nEpoch : 3 --------- Loss : 0.6572718024253845\nEpoch : 4 --------- Loss : 0.5554602742195129\nEpoch : 5 --------- Loss : 0.8258687257766724\nEpoch : 6 --------- Loss : 0.6683531999588013\nEpoch : 7 --------- Loss : 0.5981622338294983\nEpoch : 8 --------- Loss : 0.7549988031387329\nEpoch : 9 --------- Loss : 0.58006352186203\nEpoch : 10 --------- Loss : 0.6024667620658875\nEpoch : 11 --------- Loss : 0.6316583156585693\nEpoch : 12 --------- Loss : 0.7649912238121033\nEpoch : 13 --------- Loss : 0.6327900886535645\nEpoch : 14 --------- Loss : 0.6328426599502563\nEpoch : 15 --------- Loss : 0.7069187760353088\nEpoch : 16 --------- Loss : 0.5855089426040649\nEpoch : 17 --------- Loss : 0.5871124863624573\nEpoch : 18 --------- Loss : 0.5200592279434204\nEpoch : 19 --------- Loss : 0.628982424736023\nEpoch : 20 --------- Loss : 0.7118790149688721\nEpoch : 21 --------- Loss : 0.5207014083862305\nEpoch : 22 --------- Loss : 0.4814932942390442\nEpoch : 23 --------- Loss : 0.7301430106163025\nEpoch : 24 --------- Loss : 0.5224534273147583\nEpoch : 25 --------- Loss : 0.486074835062027\nEpoch : 26 --------- Loss : 0.5937310457229614\nEpoch : 27 --------- Loss : 0.3833169937133789\nEpoch : 28 --------- Loss : 0.7652176022529602\nEpoch : 29 --------- Loss : 0.7679680585861206\nEpoch : 30 --------- Loss : 0.5556719899177551\nEpoch : 31 --------- Loss : 0.6814257502555847\nEpoch : 32 --------- Loss : 0.588313102722168\nEpoch : 33 --------- Loss : 0.5307689309120178\nEpoch : 34 --------- Loss : 0.6145136952400208\nEpoch : 35 --------- Loss : 0.5861746072769165\nEpoch : 36 --------- Loss : 0.3313731551170349\nEpoch : 37 --------- Loss : 0.38560834527015686\nEpoch : 38 --------- Loss : 0.49153900146484375\nEpoch : 39 --------- Loss : 0.34985020756721497\nEpoch : 40 --------- Loss : 0.31842270493507385\nEpoch : 41 --------- Loss : 0.6039926409721375\nEpoch : 42 --------- Loss : 0.4093392491340637\nEpoch : 43 --------- Loss : 0.44115695357322693\nEpoch : 44 --------- Loss : 0.5945017337799072\nEpoch : 45 --------- Loss : 0.3624360263347626\nEpoch : 46 --------- Loss : 0.6667025089263916\nEpoch : 47 --------- Loss : 0.737789511680603\nEpoch : 48 --------- Loss : 0.6066271066665649\nEpoch : 49 --------- Loss : 0.25011515617370605\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Prediction code\n\nX_test_tensor = torch.tensor(test_data_fe, dtype=torch.float32)\n\nmodel.eval()\n\nwith torch.no_grad():  # No gradients needed for inference\n    logits = model(X_test_tensor)  # Forward pass\n    probabilities = torch.sigmoid(logits)  # Apply Sigmoid (for binary classification)\n\n# Convert to binary labels (0 or 1) based on threshold 0.5\npredictions = (probabilities > 0.5).int()\n\nprobabilities = torch.nan_to_num(probabilities, nan=0.5)\n\nprint(torch.isnan(probabilities).sum())  # Count NaN values\nprint(torch.isinf(probabilities).sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T19:04:33.357054Z","iopub.execute_input":"2025-03-10T19:04:33.357451Z","iopub.status.idle":"2025-03-10T19:04:33.393909Z","shell.execute_reply.started":"2025-03-10T19:04:33.357413Z","shell.execute_reply":"2025-03-10T19:04:33.392338Z"}},"outputs":[{"name":"stdout","text":"tensor(0)\ntensor(0)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Concatenation\n\nfinal_dataframe = np.concatenate((np.array(indices).reshape(-1, 1), probabilities.numpy()), axis = 1)\nsubmission = pd.DataFrame(final_dataframe, columns = [\"id\", \"rainfall\"])\nsubmission[\"id\"] = submission[\"id\"].astype(int)\nsubmission.to_csv(\"submission.csv\", index = False)\n\nsubmission.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T19:04:33.395136Z","iopub.execute_input":"2025-03-10T19:04:33.395482Z","iopub.status.idle":"2025-03-10T19:04:33.417941Z","shell.execute_reply.started":"2025-03-10T19:04:33.395453Z","shell.execute_reply":"2025-03-10T19:04:33.416745Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"id          0\nrainfall    0\ndtype: int64"},"metadata":{}}],"execution_count":11}]}