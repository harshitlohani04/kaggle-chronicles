{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-12T14:14:10.993774Z","iopub.execute_input":"2024-06-12T14:14:10.994214Z","iopub.status.idle":"2024-06-12T14:14:11.005517Z","shell.execute_reply.started":"2024-06-12T14:14:10.994180Z","shell.execute_reply":"2024-06-12T14:14:11.004081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dsTrain = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ndsTest = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ndsTest2 = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ndsTest.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-06-12T14:14:15.258569Z","iopub.execute_input":"2024-06-12T14:14:15.259033Z","iopub.status.idle":"2024-06-12T14:14:15.285887Z","shell.execute_reply.started":"2024-06-12T14:14:15.258999Z","shell.execute_reply":"2024-06-12T14:14:15.284811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dsTrain.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-06-12T14:14:18.685153Z","iopub.execute_input":"2024-06-12T14:14:18.685550Z","iopub.status.idle":"2024-06-12T14:14:18.696393Z","shell.execute_reply.started":"2024-06-12T14:14:18.685522Z","shell.execute_reply":"2024-06-12T14:14:18.695033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\ncolToDrop = [\"Cabin\", \"Name\", \"Ticket\", \"PassengerId\"]\ndsTrain.drop(columns = colToDrop, inplace = True)\ndsTest.drop(columns = colToDrop, inplace = True)\n\nsi = SimpleImputer(strategy = \"mean\")\ndsTrain[[\"Age\"]] = si.fit_transform(dsTrain[[\"Age\"]])\ndsTest[[\"Age\"]] = si.fit_transform(dsTest[[\"Age\"]])\ndsTest[[\"Fare\"]] = si.fit_transform(dsTest[[\"Fare\"]])\n\ndsTrain = dsTrain.dropna()\ndsTest = dsTest.dropna()\ndsTest","metadata":{"execution":{"iopub.status.busy":"2024-06-12T14:14:22.179962Z","iopub.execute_input":"2024-06-12T14:14:22.180450Z","iopub.status.idle":"2024-06-12T14:14:22.228113Z","shell.execute_reply.started":"2024-06-12T14:14:22.180413Z","shell.execute_reply":"2024-06-12T14:14:22.226517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\n\ndsTrainY = dsTrain.iloc[:, 0].values\ndsTrainX = dsTrain.iloc[:, 1:].values\ndsTest.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-06-12T14:14:26.511597Z","iopub.execute_input":"2024-06-12T14:14:26.512005Z","iopub.status.idle":"2024-06-12T14:14:26.524459Z","shell.execute_reply.started":"2024-06-12T14:14:26.511975Z","shell.execute_reply":"2024-06-12T14:14:26.522983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\n\nct = ColumnTransformer(transformers = [(\"encoder\", OneHotEncoder(), [1,6])], remainder = \"passthrough\")\ndsTrainX = ct.fit_transform(dsTrainX)\ndsTest = ct.fit_transform(dsTest)\npd.DataFrame(dsTest).isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-06-12T14:14:29.921566Z","iopub.execute_input":"2024-06-12T14:14:29.921989Z","iopub.status.idle":"2024-06-12T14:14:29.944366Z","shell.execute_reply.started":"2024-06-12T14:14:29.921957Z","shell.execute_reply":"2024-06-12T14:14:29.942989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(dsTrainY)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T14:14:33.663164Z","iopub.execute_input":"2024-06-12T14:14:33.663593Z","iopub.status.idle":"2024-06-12T14:14:33.676538Z","shell.execute_reply.started":"2024-06-12T14:14:33.663558Z","shell.execute_reply":"2024-06-12T14:14:33.675234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscTrain = StandardScaler()\nscTest = StandardScaler()\n\ndsTrainX[:, 5] = scTrain.fit_transform(dsTrainX[:, 5].reshape(-1, 1)).flatten()\ndsTrainX[:, 9] = scTrain.fit_transform(dsTrainX[:, 9].reshape(-1, 1)).flatten()\ndsTrainX[:, 6] = scTrain.fit_transform(dsTrainX[:, 6].reshape(-1, 1)).flatten()\ndsTest[:, 5] = scTest.fit_transform(dsTest[:, 5].reshape(-1, 1)).flatten()\ndsTest[:, 9] = scTest.fit_transform(dsTest[:, 9].reshape(-1, 1)).flatten()\ndsTest[:, 6] = scTest.fit_transform(dsTest[:, 6].reshape(-1, 1)).flatten()\n\nprint(pd.DataFrame(dsTest))","metadata":{"execution":{"iopub.status.busy":"2024-06-12T14:14:36.869088Z","iopub.execute_input":"2024-06-12T14:14:36.869514Z","iopub.status.idle":"2024-06-12T14:14:36.899819Z","shell.execute_reply.started":"2024-06-12T14:14:36.869481Z","shell.execute_reply":"2024-06-12T14:14:36.898475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nrfr = RandomForestRegressor(n_estimators=1000, max_depth=7, random_state=42)\nrfr.fit(dsTrainX, dsTrainY)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T14:14:40.234796Z","iopub.execute_input":"2024-06-12T14:14:40.235270Z","iopub.status.idle":"2024-06-12T14:14:43.089194Z","shell.execute_reply.started":"2024-06-12T14:14:40.235233Z","shell.execute_reply":"2024-06-12T14:14:43.087925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yPred = rfr.predict(dsTest)\nyPred = [0 if val<0.5 else 1 for val in yPred]\npd.DataFrame(yPred)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T14:14:49.677197Z","iopub.execute_input":"2024-06-12T14:14:49.677620Z","iopub.status.idle":"2024-06-12T14:14:49.772335Z","shell.execute_reply.started":"2024-06-12T14:14:49.677580Z","shell.execute_reply":"2024-06-12T14:14:49.771048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dsMerged = pd.concat([dsTest2[\"PassengerId\"], pd.DataFrame(yPred)], ignore_index=True, sort=True, axis = 1)\ndsMerged.columns = [\"PassengerId\", \"Survived\"]\ndsMerged.to_csv(\"submission.csv\", index = False)\nprint(\"Hello\")","metadata":{"execution":{"iopub.status.busy":"2024-06-12T14:15:01.362752Z","iopub.execute_input":"2024-06-12T14:15:01.363192Z","iopub.status.idle":"2024-06-12T14:15:01.374296Z","shell.execute_reply.started":"2024-06-12T14:15:01.363154Z","shell.execute_reply":"2024-06-12T14:15:01.372951Z"},"trusted":true},"execution_count":null,"outputs":[]}]}