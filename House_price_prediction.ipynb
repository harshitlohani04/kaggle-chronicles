{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 5407,
          "databundleVersionId": 868283,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30732,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "House-price-prediction",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshitlohani04/kaggle-chronicles/blob/master/House_price_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'house-prices-advanced-regression-techniques:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F5407%2F868283%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240629%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240629T145431Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D45c5a60fd798a657b29051dbdb7b4dd5e92e160ec99773d5be8ac614c1e284a814d62feccd5bdc93bbe493d41db9ff9476ba9bbf0935d02e8af1efce5896bd1f32e32c5733f6e20b9f8f61aa45516d6074727cb4536b9597ab1089ccdc80d038ac725142277addf94736fdbe464539c4bb1162e54885b53001c8da676bcd6f89be5b0b14172c23f9d04e79c80b4b39004b464e7ca0f12adac2ecd8c8736821c00ace7b731b5059894dcdefd59e3a8c2cc3ae5c53b4fa4828ae9d633aa9729a65d8cc73e807a7c12e484519f6ca4119882cc5065876419bfa4003d64d9969bcfed6b58f67be8e7e6a94baae321c736ad8fcac527164740db32458fd83dcad9562'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "6QqPVdgYfaoH"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-06-19T10:18:25.304727Z",
          "iopub.execute_input": "2024-06-19T10:18:25.305127Z",
          "iopub.status.idle": "2024-06-19T10:18:25.315113Z",
          "shell.execute_reply.started": "2024-06-19T10:18:25.305097Z",
          "shell.execute_reply": "2024-06-19T10:18:25.313768Z"
        },
        "trusted": true,
        "id": "Uilz9V12faoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "import pandas as pd\n",
        "\n",
        "train_data = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\")\n",
        "test_data = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\")\n",
        "train_data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T10:18:25.317347Z",
          "iopub.execute_input": "2024-06-19T10:18:25.317845Z",
          "iopub.status.idle": "2024-06-19T10:18:25.405348Z",
          "shell.execute_reply.started": "2024-06-19T10:18:25.317787Z",
          "shell.execute_reply": "2024-06-19T10:18:25.403899Z"
        },
        "trusted": true,
        "id": "HkzMguh_faoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting to know the data better"
      ],
      "metadata": {
        "id": "qORWvf_SfaoP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Checking for only those columns that majorly have null vals in them***"
      ],
      "metadata": {
        "id": "iMnVJWahfaoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols_with_null = []\n",
        "cols = train_data.columns\n",
        "for i in range(len(cols)):\n",
        "    if train_data[cols[i]].isnull().sum() / len(train_data[cols[i]]) >=0.5:\n",
        "        cols_with_null.append((cols[i], train_data[cols[i]].isnull().sum()))\n",
        "\n",
        "\n",
        "cols_to_drop = [item[0] for item in cols_with_null]\n",
        "train_data = train_data.drop(columns = cols_to_drop, axis=1)\n",
        "test_data = test_data.drop(columns = cols_to_drop, axis=1)\n",
        "train_data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T10:18:25.406988Z",
          "iopub.execute_input": "2024-06-19T10:18:25.407429Z",
          "iopub.status.idle": "2024-06-19T10:18:25.46377Z",
          "shell.execute_reply.started": "2024-06-19T10:18:25.407372Z",
          "shell.execute_reply": "2024-06-19T10:18:25.462257Z"
        },
        "trusted": true,
        "id": "lzqZUbglfaoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Dropping the cols that contain more than 95% of a certain val***"
      ],
      "metadata": {
        "id": "8UDC7Im7faoS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tried to use this for knowing the dist of the data in a col but the data is huge to be plotted so idea dropped\n",
        "def Freq_plot(df):\n",
        "    # select_dtypes(include=[\"object\", \"categorical\", \"int64\"]) --> returns a dataset with columns that contain these types of data.\n",
        "    \n",
        "    data_cols = df.select_dtypes(include=[\"int64\"]).columns  # Creating the array of cols\n",
        "    data_col_len = len(data_cols)\n",
        "    print(data_col_len)\n",
        "    \n",
        "    # Approach used in here is using pandas and plt\n",
        "    for i, col in enumerate(data_cols, 1):\n",
        "        plt.subplot(7, 5, i) # Creating subplots for all cols\n",
        "  \n",
        "        # df[column].value_counts() --> counts the frequency of the vals in that column\n",
        "        \n",
        "        df[col].value_counts().plot(kind='bar', color='skyblue', edgecolor='black')\n",
        "        plt.title(f'Distribution of {col}')\n",
        "        plt.xlabel(col)\n",
        "        plt.ylabel('Frequency')\n",
        "        \n",
        "    plt.show()\n",
        "        \n",
        "Freq_plot(train_data)"
      ],
      "metadata": {
        "id": "DKCHVvnvfaoT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Another way of eliminating the cols that contain more than 95% of a certain val in cols with object datatype"
      ],
      "metadata": {
        "id": "X0BNF84nfaoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "obj_cols = train_data.select_dtypes(include = [\"object\"]).columns\n",
        "# For dropping the cols that contain redundant data >95%\n",
        "for col in obj_cols:\n",
        "    max_val = train_data[col].value_counts(normalize = True).max()\n",
        "    if max_val>0.9:\n",
        "        train_data = train_data.drop(columns = col, axis=1)\n",
        "        test_data = test_data.drop(columns = col, axis=1)\n",
        "train_data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T10:18:25.465472Z",
          "iopub.execute_input": "2024-06-19T10:18:25.465826Z",
          "iopub.status.idle": "2024-06-19T10:18:25.554244Z",
          "shell.execute_reply.started": "2024-06-19T10:18:25.465799Z",
          "shell.execute_reply": "2024-06-19T10:18:25.552991Z"
        },
        "trusted": true,
        "id": "apIy_nCnfaoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T10:18:25.558426Z",
          "iopub.execute_input": "2024-06-19T10:18:25.559025Z",
          "iopub.status.idle": "2024-06-19T10:18:25.582961Z",
          "shell.execute_reply.started": "2024-06-19T10:18:25.558976Z",
          "shell.execute_reply": "2024-06-19T10:18:25.581105Z"
        },
        "trusted": true,
        "id": "Y6QJNQMtfaoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.select_dtypes(include=[\"int64\"])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T10:18:25.587098Z",
          "iopub.execute_input": "2024-06-19T10:18:25.588768Z",
          "iopub.status.idle": "2024-06-19T10:18:25.614358Z",
          "shell.execute_reply.started": "2024-06-19T10:18:25.588697Z",
          "shell.execute_reply": "2024-06-19T10:18:25.612613Z"
        },
        "trusted": true,
        "id": "AxdOZO_rfaoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Handling missing vals in the float columns**"
      ],
      "metadata": {
        "id": "ShO3FnNIfaoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "si = SimpleImputer(strategy = \"mean\")\n",
        "\n",
        "imputed_cols_train = si.fit_transform(train_data.select_dtypes(include=[\"float\"]))\n",
        "imputed_cols_test = si.fit_transform(test_data.select_dtypes(include=[\"float\"]))\n",
        "\n",
        "train_data[train_data.select_dtypes(include=[\"float\"]).columns] = pd.DataFrame(imputed_cols_train, columns=train_data.select_dtypes(include=[\"float\"]).columns)\n",
        "test_data[test_data.select_dtypes(include=[\"float\"]).columns] = pd.DataFrame(imputed_cols_test, columns=test_data.select_dtypes(include=[\"float\"]).columns)\n",
        "test_data.select_dtypes(include=[\"float\"])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T10:18:25.616265Z",
          "iopub.execute_input": "2024-06-19T10:18:25.617282Z",
          "iopub.status.idle": "2024-06-19T10:18:25.660876Z",
          "shell.execute_reply.started": "2024-06-19T10:18:25.617246Z",
          "shell.execute_reply": "2024-06-19T10:18:25.659306Z"
        },
        "trusted": true,
        "id": "CMCxs7Q8faoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obj_cols = train_data.select_dtypes(include=[\"object\"]).columns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "for col in obj_cols:\n",
        "    train_data[col] = le.fit_transform(train_data[col])\n",
        "    test_data[col] = le.fit_transform(test_data[col])\n",
        "test_data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T10:18:25.663078Z",
          "iopub.execute_input": "2024-06-19T10:18:25.663638Z",
          "iopub.status.idle": "2024-06-19T10:18:25.735261Z",
          "shell.execute_reply.started": "2024-06-19T10:18:25.663601Z",
          "shell.execute_reply": "2024-06-19T10:18:25.733894Z"
        },
        "trusted": true,
        "id": "ve3lPpUPfaoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now that all columns have been non-nullified we seperate the features and the prediction col"
      ],
      "metadata": {
        "id": "CqV0UA2lfaoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y = train_data[\"SalePrice\"]\n",
        "X = train_data.drop(columns = [\"Id\", \"SalePrice\"], axis=1)\n",
        "\n",
        "ids = test_data[\"Id\"]\n",
        "test_data = test_data.drop(columns = [\"Id\"], axis=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T10:18:25.736925Z",
          "iopub.execute_input": "2024-06-19T10:18:25.737337Z",
          "iopub.status.idle": "2024-06-19T10:18:25.748798Z",
          "shell.execute_reply.started": "2024-06-19T10:18:25.737309Z",
          "shell.execute_reply": "2024-06-19T10:18:25.747463Z"
        },
        "trusted": true,
        "id": "iyqtdHkgfaoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Splitting the data into training and test split**"
      ],
      "metadata": {
        "id": "TT--NiVGfaoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T10:18:25.750312Z",
          "iopub.execute_input": "2024-06-19T10:18:25.751054Z",
          "iopub.status.idle": "2024-06-19T10:18:25.765268Z",
          "shell.execute_reply.started": "2024-06-19T10:18:25.751012Z",
          "shell.execute_reply": "2024-06-19T10:18:25.763758Z"
        },
        "trusted": true,
        "id": "n0M3bNMzfaoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaled_Xtrain = scaler.fit_transform(X_train)\n",
        "scaled_Xtest = scaler.transform(X_test)\n",
        "\n",
        "scaler_test = StandardScaler()\n",
        "test_matrix = scaler_test.fit_transform(test_data)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T10:18:25.767072Z",
          "iopub.execute_input": "2024-06-19T10:18:25.767623Z",
          "iopub.status.idle": "2024-06-19T10:18:25.796286Z",
          "shell.execute_reply.started": "2024-06-19T10:18:25.76758Z",
          "shell.execute_reply": "2024-06-19T10:18:25.794721Z"
        },
        "trusted": true,
        "id": "sDsGmxRBfaoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Creating the model for prediction***"
      ],
      "metadata": {
        "id": "AOiypJFOfaoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Trying out ridge regression and lasso regression\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "\n",
        "ls = Lasso(alpha = 2.84142) # Producing A BETTER MODEL than ridge regression\n",
        "# rdg = Ridge(alpha = 5)\n",
        "ls.fit(scaled_Xtrain, Y_train)\n",
        "pred = ls.predict(test_matrix)\n",
        "prediction_arr = []\n",
        "for i in range(len(ids)):\n",
        "    prediction_arr.append([ids[i], pred[i]])\n",
        "final_pred = pd.DataFrame(prediction_arr, columns = [\"Id\", \"SalePrice\"])\n",
        "final_pred.to_csv(\"submission.csv\", index=False)\n",
        "final_pred"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-19T10:18:25.798273Z",
          "iopub.execute_input": "2024-06-19T10:18:25.798789Z",
          "iopub.status.idle": "2024-06-19T10:18:25.897604Z",
          "shell.execute_reply.started": "2024-06-19T10:18:25.798747Z",
          "shell.execute_reply": "2024-06-19T10:18:25.896219Z"
        },
        "trusted": true,
        "id": "ERhE-zaBfaoW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}